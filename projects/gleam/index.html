<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes">
  <meta name="keywords" content="Active Mapping, Next-Best-View, Exploration Policy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    h1 {
      color: #8C1515;
    }
  </style>
  <title>GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- GoogleAPI
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">-->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>








<body>


<!-- <div class="full-page-image">
  <video id="bg-video" autoplay loop muted playsinline>
      <source src="assets/videos/full_screen.mp4" type="video/mp4">
  </video>
  <div class="overlay"></div>
  <div class="content" style="padding: 0 20px">
      <h1>BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities</h1>
  </div>
</div> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- Title -->
          <!-- <h1 class="title is-1 publication-title">GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes</h1> -->
          <!-- <h1 class="title is-1 publication-title" style="color: #8C1515; line-height: 1.1">
          GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes</h1> -->

          <h1 class="title is-1 publication-title" style="color: #8C1515; 
          line-height: 1.3;
          margin-left: -35.0%;
          margin-right: -35.0%;">
          GLEAM: Learning Generalizable Exploration Policy for Active Mapping <br> in Complex 3D Indoor Scenes
        </h1>

          <!-- <h2 class="subtitle is-3" style="margin-bottom: 0;">CVPR 2024</h2> -->
          <!-- <span class="text-border-title" style="font-size: 2em;">CVPR 2024</span> -->
          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://xiao-chen.tech/" target="_blank">Xiao Chen</a><sup>1,2</sup>,</span>
            <span class="author-block"><a href="https://tai-wang.github.io/" target="_blank">Tai Wang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://quanyili.github.io/" target="_blank">Quanyi Li</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://taohuang13.github.io/" target="_blank">Tao Huang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://oceanpang.github.io/" target="_blank">Jiangmiao Pang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://tianfan.info/" target="_blank">Tianfan Xue</a><sup>1</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup>Shanghai AI Laboratory,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="./static/paper/GenNBV.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->

              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.16174"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zjwzcx/GLEAM" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Data Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1SUcDy8hwluEBpTtKZ3_83ySKnLlsZ4hi?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=GP0PdaXs93E"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (YouTube)</span>
                </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.bilibili.com/video/BV1Vz421Z7os/?vd_source=03a8e4a181629720c5623ae40bda6ea9"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (Bilibili)</span>
                </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>







<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <hr class="text-border-line">
    </div>
    <div class="hero-body">
      <video id="teaser"               
               controls
               muted
               preload
               playsinline height="100%">
        <source src="./static/videos/gennbv_v9_comp.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section> -->



<!-- Teaser -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- <div class="columns is-centered has-text-centered">
      <h1 class="title is-1" style="color: #8C1515;">GLEAM-Bench</h1>
    </div> -->

    <div class="content has-text-centered">
      <img width="140%" src="./static/images/Fig_Teaser.png"">
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          We introduce <u><b>GLEAM</b></u>, a unified generalizable exploration policy for complex 3D indoor scenes trained on our benchmark <u><b>GLEAM-Bench</b></u> including 1024 diverse training scenes. We conduct a cross-dataset evaluation to generalize our policy to an unseen real-scan scene from Matterport3D, scanning 83.67% areas using 40 keyframes, without any fine-tuning and prior knowledge.
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-1" style="color: #8C1515;">Abstract</h1>
        <div class="content has-text-justified">
            Generalizable active mapping in complex unknown environments remains a critical challenge for mobile robots. 
            Existing methods, constrained by limited training data and conservative exploration strategies, struggle to generalize across scenes with diverse layouts and complex connectivity.
            To enable scalable training and reliable evaluation, we present <strong>GLEAM-Bench</strong>, the first large-scale benchmark with 1,152 diverse 3D scenes from synthetic and real datasets. 
            In this work, we propose <strong>GLEAM</strong>, a <u>g</u>enera<u>l</u>izable <u>e</u>xploration policy for <u>a</u>ctive <u>m</u>apping.
            Its superior generalizability comes from our semantic representations, long-term goal and randomized strategies. 
            It significantly outperforms state-of-the-art methods, achieving 68.16% coverage (+11.41%) with efficient trajectories, and improved mapping accuracy on 128 unseen complex scenes.
        </div>
      </div>
    </div>

    <!-- <div class="content has-text-centered">
      <img width="140%" src="./static/images/Fig_Teaser.png"">
    </div> -->

    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          We introduce <u><b>GLEAM</b></u>, a unified generalizable exploration policy for complex 3D indoor scenes trained on our benchmark <u><b>GLEAM-Bench</b></u> including 1024 diverse training scenes. We conduct a cross-dataset evaluation to generalize our policy to an unseen real-scan scene from Matterport3D, scanning 83.67% areas using 40 keyframes, without any fine-tuning and prior knowledge.
        </div>
      </div>
    </div> -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h1 class="title is-1" style="color: #8C1515;">GLEAM-Bench</h1>
    </div>
    <div class="content has-text-centered">
      <img width="140%" src="./static/images/Fig_Bench.png">
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          The overview of our framework. Trained on 1,024 diverse indoor scenes, <u><b>GLEAM</b></u> processes depth observations and agents' poses to iteratively update a global map. An egocentric map is extracted and augmented with exploration frontiers to capture semantic exploration cues. A lightweight Transformer encoder then analyzes the egocentric map and trajectory history to predict the long-term goals. The reward function of coverage is computed by the global map and ground-truth occupancy map.
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h1 class="title is-1" style="color: #8C1515;">GLEAM</h1>
    </div>
    <div class="content has-text-centered">
      <img width="140%" src="./static/images/Fig_Method.png">
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          The overview of our framework. Trained on 1,024 diverse indoor scenes, <u><b>GLEAM</b></u> processes depth observations and agents' poses to iteratively update a global map. An egocentric map is extracted and augmented with exploration frontiers to capture semantic exploration cues. A lightweight Transformer encoder then analyzes the egocentric map and trajectory history to predict the long-term goals. The reward function of coverage is computed by the global map and ground-truth occupancy map.
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h1 class="title is-1" style="color: #8C1515;">Generalizability Evaluation</h1>
      </div>
      <div class="content has-text-centered">
        <img width="100%" src="./static/images/exp_main_table.png"">
      </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <!-- Table 1. Evaluation results of Next-Best-View policies for active 3D reconstruction on <b>Houses3K</b> and the house category from <b>OmniObject3D</b> (cross-dataset generalization).  -->
          Evaluation results of Next-Best-View policies for active 3D reconstruction on <b>Houses3K</b> and the house category from <b>OmniObject3D</b> (cross-dataset generalization).
          The number of views is set to 30 and 20 for Houses3K and OmniObject3D, respectively.<br>
          "<b>*</b>": the policy is trained on Houses3K training set and evaluated on holdout Houses3K test set and OmniObject3D house category.<br>
          "<b>†</b>": the policy heavily relies on optimized per-scene representation (NeRF), thus is directly trained and evaluated on testing objects.
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      </div>
      <div class="content has-text-centered">
        <img width="150%" src="./static/images/Fig_Vis.png"">
      </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          The visualization results of unseen 3D objects reconstructed by Scan-RL and our model to compare the generalizability. (a) Unseen buildings from the test set of Houses3K. (b) Unseen buildings from OmniObject3D.
          It's quite obvious that some parts of the model reconstructed by Scan-RL are wrong or missing. For example, the second object in the first row has a pillar in the wrong shape. Scan-RL fails to reconstruct the roof edge for the fourth object from OmniObject3D, as shown in the third row.
        </div>
      </div>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      </div>
      <div class="content has-text-centered">
        <img width="130%" src="./static/images/Fig_Vis_City.png"">
      </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          The visualization results of an unseen 3D outdoor scene with enormous details from Objaverse, reconstructed by Uncertainty-guided, Scan-RL and our model.
          Compared to the uncertainty-guided method and Scan-RL, the scene reconstructed by our method is more watertight and has fewer holes on the ground and building surface, especially in the region highlighted by the red box.
        </div>
      </div>
    </div>
  </div>
</section>












<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h1 class="title is-1" style="color: #8C1515;">Ablation Study</h1>
    </div>

    <div class="content has-text-centered">
      <img width="60%" src="./static/images/exp_abl_repre.png"">
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <!-- Table 2. Ablation studies of representation categories in our framework on unseen Houses3K test set. -->
          Ablation studies of representation categories in our framework on unseen Houses3K test set.
        </div>
      </div>
    </div>


    <div class="content has-text-centered">
      <img width="55%" src="./static/images/exp_abl_scaling.png"">
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <!-- Table 4. Ablation studies of the number of training objects in our framework on unseen OmniObject3D house category. -->
          Ablation studies of the number of training objects in our framework on OmniObject3D house category.
        </div>
      </div>
    </div>


    <div class="content has-text-centered">
      <img width="80%" src="./static/images/Fig_Scaling.png"">
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          The curve of coverage (%) with the increasing number of training objects on OmniObject3D house category.
        </div>
      </div>
    </div>
  </div>
</section>













<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title" style="color: #8C1515;">Citation</h2>
    If you find this project helpful, please cite us:
    <pre><code>@article{chen2024gennbv,
  author    = {Chen, Xiao and Li, Quanyi and Wang, Tai and Xue, Tianfan and Pang, Jiangmiao},
  title     = {GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes},
  journal   = {arXiv preprint arXiv:2402.16174},
  year      = {2025},
}</code></pre>
  </div>
</section> -->


<!-- <section class="section">
  <div class="container is-max-desktop">
    <h3 class="title is-3">Acknowledgement</h2>
    <div class="content has-text-justified">
      <p>
        We extend our sincere gratitude to Yaokun Li, Chenjian Gao, and Ruikang Li for their insightful advice about visualization.
      </p>
    </div>
  </div>
</section> -->




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template/">Academic Project Page Template</a>
            which was adopted from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
          </p>
          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=_Oc9F3kg19qBNmKgX28mdlmSyRKP3q24f-fNiCZ4qaE'></script>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>